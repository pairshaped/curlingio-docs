"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"passwordless-auth-done-right","metadata":{"permalink":"/blog/passwordless-auth-done-right","source":"@site/blog/2026-02-20-passwordless-auth-done-right.md","title":"Passwordless Auth, Done Right","description":"Curling IO has been passwordless since Version 2. No passwords to remember, no passwords to steal, no password reset flows. You enter your email, we send you a short-lived login code, and you\'re in. It\'s been working well for over a decade, and for Version 3 we\'re keeping the same approach while fixing some rough edges and adding multi-email support.","date":"2026-02-20T00:00:00.000Z","tags":[{"inline":true,"label":"foundation","permalink":"/blog/tags/foundation"},{"inline":true,"label":"authentication","permalink":"/blog/tags/authentication"},{"inline":true,"label":"gleam","permalink":"/blog/tags/gleam"},{"inline":true,"label":"security","permalink":"/blog/tags/security"}],"readingTime":10.74,"hasTruncateMarker":true,"authors":[{"name":"Dave Rapin","title":"Founder @ Curling IO","imageURL":"https://avatars.githubusercontent.com/u/1202?v=4","key":"dave","page":null}],"frontMatter":{"slug":"passwordless-auth-done-right","title":"Passwordless Auth, Done Right","authors":["dave"],"tags":["foundation","authentication","gleam","security"]},"unlisted":false,"nextItem":{"title":"Bilingual by Design","permalink":"/blog/bilingual-by-design"}},"content":"Curling IO has been passwordless since Version 2. No passwords to remember, no passwords to steal, no password reset flows. You enter your email, we send you a short-lived login code, and you\'re in. It\'s been working well for over a decade, and for Version 3 we\'re keeping the same approach while fixing some rough edges and adding multi-email support.\\n\\nBut first, let\'s talk about why we made this <u>*controversial decision*</u> in the first place.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why Not Passwords?\\n\\nThe conventional wisdom is that passwords are the \\"real\\" way to authenticate and login links are a shortcut. We think it\'s the opposite. Passwords are the shortcut, and they create more problems than they solve. We\'re not alone. Slack, Notion, Medium, and Substack all use passwordless login links as their primary authentication method.\\n\\n**Passwords get reused.** Study after study shows that most people reuse the same password across multiple sites. When any one of those sites gets breached, attackers try those credentials everywhere else. This isn\'t a theoretical risk. It happens constantly, and it\'s the number one way accounts get compromised. As an application developer, you can\'t control what your users do on other sites, but you inherit the risk.\\n\\n**Passwords get phished.** A convincing fake login page can harvest credentials at scale. Login links are inherently resistant to phishing because there\'s no credential to hand over. The code is short-lived and tied to a specific email address.\\n\\n**Passwords require just as much email verification.** Here\'s the thing people overlook: even with passwords, you still need to verify the user\'s email. Otherwise anyone can create an account with someone else\'s email address. So you end up building the same email verification flow that login links use, plus the password management on top of it. You\'re not avoiding email. You\'re adding a password layer on top of it.\\n\\n**The industry agrees.** Look at what banks and other high-security sites do now: even after you enter your email and password, they send you a one-time code via text or email. Password alone isn\'t enough anymore, so they\'ve added the exact same verification step we use. Some have a \\"remember this device for 2 weeks\\" checkbox, but in practice it rarely works. You log in an hour later after your session times out and they\'re sending you another code. It\'s not just frustrating. It reveals that the password itself has become a meaningless step. The one-time code is doing the actual authentication. The password is just theater you have to sit through before you get to the part that matters. We skip it entirely.\\n\\n**Passwords add surface area.** With passwords, you need: secure hashing (bcrypt/argon2), a \\"forgot password\\" flow (which is itself a login link), password strength validation, brute force protection on the login form, and secure storage. With login links, you need: token generation and hashing. That\'s it. Less code means fewer bugs and fewer attack vectors.\\n\\n**\\"But what about password managers?\\"** Password managers are great. They solve the reuse and phishing problems for users who use them. But most users don\'t. And for the curling club use case, where members log in a handful of times per season, asking them to set up and maintain a password manager is unrealistic. Login links meet users where they are.\\n\\n## How Login Links Are Secure\\n\\nA login link is a short-lived code sent to your email. The security model rests on a simple assumption: if you can read email sent to that address, you control that address. This is the same assumption that password reset flows rely on, but we cut out the middleman.\\n\\nHere\'s what makes the implementation secure:\\n\\n**High-entropy tokens.** Each login code is drawn from a high-entropy space, but it doesn\'t need to be astronomical because of the next two points. The token generator uses Gleam\'s binary pattern matching to map cryptographically random bytes to an unambiguous alphabet:\\n\\n```gleam\\npub fn generate_token() -> String {\\n  let alphabet_size = string.length(token_alphabet)\\n  crypto.strong_random_bytes(token_length)\\n  |> pick_chars(alphabet_size, \\"\\")\\n}\\n\\nfn pick_chars(bytes: BitArray, alphabet_size: Int, acc: String) -> String {\\n  case bytes {\\n    <<b, rest:bits>> -> {\\n      let idx = b % alphabet_size\\n      let ch = string.slice(token_alphabet, idx, 1)\\n      pick_chars(rest, alphabet_size, acc <> ch)\\n    }\\n    _ -> acc\\n  }\\n}\\n```\\n\\n**Aggressive rate limiting.** Authentication attempts are tightly rate limited across multiple layered time windows. Brute-forcing the token space is completely impractical. Each window is checked in sequence using Gleam\'s `use` syntax. If any window is exceeded, it short-circuits and returns the retry-after time without checking the rest:\\n\\n```gleam\\npub fn check_verification_attempt(\\n  limiter: RateLimiter,\\n  email: String,\\n  now: Int,\\n) -> Result(Nil, Int) {\\n  let key = key_prefix <> string.lowercase(email)\\n  use _ <- result.try(check(limiter, key, attempts_per_minute, 60, now))\\n  use _ <- result.try(check(limiter, key, attempts_per_15_minutes, 900, now))\\n  use _ <- result.try(check(limiter, key, attempts_per_hour, 3600, now))\\n  check(limiter, key, attempts_per_day, 86_400, now)\\n}\\n```\\n\\n**Short-lived.** Each code expires quickly. After verification, the token hash is cleared from the database. There\'s no window for replay attacks.\\n\\n**Constant-time comparison.** We look up the email row first, then compare the submitted token hash against the stored hash using Gleam\'s `crypto.secure_compare`. This takes the same amount of time regardless of where the first mismatch occurs, preventing timing attacks that could leak information about partial matches. If the current token doesn\'t match, we check the previous token, not to log them in, but to return a specific error message guiding the user to check for a more recent email:\\n\\n```gleam\\nlet hashes_match =\\n  crypto.secure_compare(\\n    bit_array.from_string(submitted_hash),\\n    bit_array.from_string(stored_hash),\\n  )\\n\\ncase hashes_match {\\n  True ->\\n    case row.token_expires_at {\\n      Some(expires_at) if expires_at > now ->\\n        complete_verification(conn, row, now)\\n      _ -> Error(ExpiredToken)\\n    }\\n  False ->\\n    case row.previous_token_hash {\\n      Some(prev_hash) -> {\\n        let prev_match =\\n          crypto.secure_compare(\\n            bit_array.from_string(submitted_hash),\\n            bit_array.from_string(prev_hash),\\n          )\\n        case prev_match {\\n          True -> Error(SupersededToken)\\n          False -> Error(InvalidToken)\\n        }\\n      }\\n      None -> Error(InvalidToken)\\n    }\\n}\\n```\\n\\nEvery branch returns a specific error variant, and the compiler ensures we handle all of them. No forgotten edge cases. The previous token never grants access. It only exists to give a better error message than a generic \\"invalid token.\\"\\n\\n**No credential storage.** There are no passwords in our database. In a breach scenario, attackers get token hashes that are short-lived. Compare that to a password database where every hash is a target for offline cracking.\\n\\nIt\'s also worth noting that the main vulnerability of login links is a compromised email account. But if someone\'s email is compromised, they have much bigger problems than their Curling IO profile. And a password-based system is equally vulnerable in that scenario. The attacker just clicks \\"forgot password\\" and they\'re in.\\n\\nThe bottom line: login links are not a weaker form of authentication. For our use case, they\'re stronger. They eliminate entire categories of attacks (credential stuffing, phishing, password spraying) while being simpler for both users and developers.\\n\\n## Takeaways from Version 2\\n\\nVersion 2\'s login link flow is straightforward: enter your email, get a code, enter the code, you\'re in. It works. But after a decade and hundreds of thousands of users, a few pain points emerged.\\n\\n**One email, one identity.** In Version 2, your email *is* your identity. Log in with a different email, you get a different account. This has been a real source of confusion. A club manager registers with their work email, then tries to log in from their phone with their personal email, and they\'re looking at an empty account. We\'d get support requests about \\"missing registrations\\" that were really just the same person with two accounts.\\n\\n**Unhelpful error messages.** This one came up a lot. A curler would request a login link, wait a minute or two, not see the email, and request another one. The first email was usually just delayed. Many email clients only check for new mail every 5 to 15 minutes. When the first email finally arrived and they clicked it, they\'d get a generic \\"invalid token\\" error because the second request had replaced the first. They\'d wonder if they mistyped something, try again, get confused, and contact support.\\n\\n## Version 3 Adds Multiple Email Addresses\\n\\nThis is the big addition. Users can now associate multiple verified email addresses with their account:\\n\\n**Add an email.** From the account page, enter a new email address. We send a verification code using the same mechanism as login.\\n\\n**Verify it.** Enter the code. The email is now linked to your account and marked as verified. Unverified emails can\'t be used for anything.\\n\\n**Set it as primary.** Any verified email can be promoted to primary. Your primary email is what shows up across the platform, in admin dashboards, on team rosters, in email communications. Changing your primary is a single click.\\n\\n**Remove it.** Non-primary emails can be removed. You can\'t remove your primary (switch to a different one first) and you can\'t remove your last verified email (you need at least one to log in).\\n\\n**Log in with any of them.** This is the key benefit. Once you\'ve added and verified multiple emails, logging in with *any* of them resolves to the same account, the same registrations, the same history. No more duplicate accounts because you used a different email.\\n\\n### How It Works Under the Hood\\n\\nEach email row tracks a few key fields:\\n\\n```\\nemail               -- globally unique, one owner max\\nuser_id             -- nullable; not set until verified for first-time logins\\ntoken_hash          -- pending verification token\\nprevious_token_hash -- the token that was replaced (for superseded detection)\\nverified_at         -- null until verified\\n```\\n\\nThis single structure handles both login verification and email ownership.\\n\\nThe design means multi-email support was almost free. The same verification flow used for login handles email verification for logged-in users. The only difference is that the user is already set when you\'re adding an email to your existing account.\\n\\n## Superseded Token Detection\\n\\nRemember the delayed email problem from Version 2? A curler requests a link, doesn\'t see it right away, requests another, and then clicks the first one when it finally arrives. Version 3 handles this gracefully.\\n\\nWhen a new login link is requested, we don\'t just overwrite the old token. We move the current `token_hash` to `previous_token_hash` first. If someone then tries the old token, we can tell the difference:\\n\\n```gleam\\npub type AuthError {\\n  InvalidToken      // not found or already used\\n  SupersededToken   // replaced by a newer token\\n  ExpiredToken      // past expiry\\n  UserDisabled      // account disabled\\n  DatabaseError(sqlight.Error)\\n}\\n```\\n\\nA `SupersededToken` gets a specific message: \\"This code has been replaced. Check for a more recent email or request a new link.\\" Instead of leaving users confused, we point them in the right direction.\\n\\nThis is a pattern we use throughout Version 3. Gleam\'s union types let us model every possible error state explicitly, and the compiler ensures we handle all of them. No forgotten edge cases, no generic catch-all error messages.\\n\\n## OAuth (Google and Facebook)\\n\\nLogin links aren\'t the only way in. Google and Facebook login work alongside them for users who prefer one-click SSO.\\n\\nThe OAuth flow uses a central auth subdomain (`auth.curling.io`) to handle callbacks, since both providers require a fixed redirect URI. After the provider verifies the user\'s identity, we look up the email in the same table used for login links. If the email exists with a user, log them in. If not, create the user and a verified email row (OAuth emails are pre-verified by the provider).\\n\\nThe same user resolution logic, regardless of how you authenticate.\\n\\n## A Note on Rolling Your Own Auth\\n\\nWriting your own authentication is generally a bad idea. Battle-tested libraries like <a href=\\"https://github.com/heartcombo/devise\\" target=\\"_blank\\">Devise</a> (Ruby), <a href=\\"https://next-auth.js.org\\" target=\\"_blank\\">NextAuth</a> (JavaScript), and <a href=\\"https://django-allauth.readthedocs.io\\" target=\\"_blank\\">django-allauth</a> (Python) exist for good reason. They\'ve been hardened over years of real-world use and security audits. If you\'re building on a stack that has a mature auth library, use it.\\n\\nWe couldn\'t find an existing Gleam auth library that was the right fit for our specific needs, but we didn\'t design in a vacuum. We studied Devise\'s modules extensively (Lockable, Timeoutable, Trackable, Confirmable) and used them as a checklist for what a production auth system needs to handle. Every security decision we made, from constant-time comparison to layered rate limiting to email enumeration prevention, was informed by what these libraries have learned the hard way over the past decade.\\n\\n## What\'s Next\\n\\nAuthentication is foundational, but the real value of multi-email support shows up when it connects to everything else: registrations, team management, admin permissions, payment history. As we build those features, having clean user resolution across multiple emails will simplify a lot of workflows that were painful in Version 2.\\n\\nWe\'re also considering optional two-factor authentication for club administrators, via authenticator apps or SMS, for organizations that want to force an extra layer of security on accounts with administrative access.\\n\\n---\\n\\n*This is Part 3 of the Curling IO Foundation series. Next up: background jobs on the BEAM, with no Redis, no separate worker, and no additional infrastructure.*"},{"id":"bilingual-by-design","metadata":{"permalink":"/blog/bilingual-by-design","source":"@site/blog/2026-02-15-bilingual-by-design.md","title":"Bilingual by Design","description":"Curling IO serves hundreds of clubs across Canada, where English and French aren\'t optional, they\'re official languages. A club in Quebec needs a fully French experience. A national organization like Curling Canada needs both. Rails has mature i18n support and Version 2 has been fully bilingual from the start, but after a decade of maintaining around 10,000 YAML translation keys, we\'ve hit the limits of what that approach can catch: missing keys, missing translations, and unused keys that accumulate silently over time.","date":"2026-02-15T00:00:00.000Z","tags":[{"inline":true,"label":"foundation","permalink":"/blog/tags/foundation"},{"inline":true,"label":"i18n","permalink":"/blog/tags/i-18-n"},{"inline":true,"label":"gleam","permalink":"/blog/tags/gleam"},{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":6.68,"hasTruncateMarker":true,"authors":[{"name":"Dave Rapin","title":"Founder @ Curling IO","imageURL":"https://avatars.githubusercontent.com/u/1202?v=4","key":"dave","page":null}],"frontMatter":{"slug":"bilingual-by-design","title":"Bilingual by Design","authors":["dave"],"tags":["foundation","i18n","gleam","architecture"]},"unlisted":false,"prevItem":{"title":"Passwordless Auth, Done Right","permalink":"/blog/passwordless-auth-done-right"},"nextItem":{"title":"The Next Version of Curling IO","permalink":"/blog/the-next-version-of-curling-io"}},"content":"Curling IO serves hundreds of clubs across Canada, where English and French aren\'t optional, they\'re official languages. A club in Quebec needs a fully French experience. A national organization like Curling Canada needs both. Rails has mature i18n support and Version 2 has been fully bilingual from the start, but after a decade of maintaining around 10,000 YAML translation keys, we\'ve hit the limits of what that approach can catch: missing keys, missing translations, and unused keys that accumulate silently over time.\\n\\nIn Version 3, we wanted compile-time guarantees that make those problems impossible. This post covers how we designed the i18n system, why we split it into two layers, and what we changed from Version 2.\\n\\n\x3c!--truncate--\x3e\\n\\n## Two Kinds of Text, Two Different Systems\\n\\nEvery bilingual web application has two fundamentally different kinds of text:\\n\\n1. **App labels**: static UI strings like \\"Leagues\\", \\"Contact\\", \\"Email\\". These are written by developers and change at deploy time.\\n2. **Content**: user-entered data like league names, summaries, and descriptions. These are entered by club managers and may change at any time.\\n\\n| | App Labels | Content |\\n|---|---|---|\\n| **Who writes it** | Developers | Club managers |\\n| **When it changes** | At deploy time | At any time |\\n| **Where it lives** | Compiled code | Database |\\n| **Scope** | Global (all clubs) | Per-record |\\n\\nIn Version 2, app labels came from Rails i18n YAML files loaded at boot, and content was stored in per-language database columns (`name_en`, `name_fr`, `summary_en`, `summary_fr`). This worked, but had pain points we wanted to address.\\n\\n## What Version 2 Taught Us\\n\\n**The YAML files grew unwieldy.** Over the years, our `en.yml` and `fr.yml` files accumulated thousands of keys each. Finding unused keys was a manual process. Ensuring every English key had a French counterpart required discipline that occasionally slipped, resulting in untranslated UI elements showing up in production as blank strings or key paths like `en.registrations.confirm_button`.\\n\\n**Per-language columns didn\'t scale.** The `leagues` table in Version 2 has `name_en`, `name_fr`, `summary_en`, `summary_fr`, `description_en`, `description_fr`, `post_registration_message_en`, `post_registration_message_fr`, `required_reading_en`, `required_reading_fr`. That\'s 10 columns just for translated text on one table. Every new translatable field requires a migration adding two columns. If we ever added a third language, it would mean another column for every translatable field on every table.\\n\\n**Blank vs. missing was ambiguous.** When `name_fr` was empty, did the manager intentionally leave it blank, or did they just not get around to translating it? The system couldn\'t tell the difference.\\n\\n## Version 3: App Label Translations\\n\\nApp labels are compiled directly into the application. No database, no YAML files, no runtime file loading. Just Gleam code.\\n\\nThe structure is simple:\\n\\n```\\ntranslations/keys.gleam   constants for every key\\ntranslations/en.gleam     English values\\ntranslations/fr.gleam     French values\\ntranslations.gleam        builds the lookup, provides t()\\n```\\n\\n**Key constants** are `pub const` values in `keys.gleam`. This is extra code we\'ve added specifically to get compile-time correctness. Every key used in a page or language file references these constants, so a misspelled key is a compile error rather than a silent runtime bug:\\n\\n```gleam\\npub const leagues = \\"leagues\\"\\npub const contact = \\"contact\\"\\npub const email_label = \\"email_label\\"\\n```\\n\\nNotice these are flat, no nesting. In Version 2, Rails i18n keys were nested by namespace (`en.registrations.confirm_button`, `en.leagues.index.title`, etc.). In practice, the nesting added complexity without much benefit: keys were harder to grep for, reorganizing namespaces meant touching multiple files, and deeply nested YAML was error-prone to edit. Flat keys are simpler to search, simpler to maintain, and work just as well with thousands of entries.\\n\\n**Language files** map those constants to translated values:\\n\\n```gleam\\n// en.gleam\\n#(k.leagues, \\"Leagues\\"),\\n#(k.contact, \\"Contact\\"),\\n#(k.email_label, \\"Email\\"),\\n\\n// fr.gleam\\n#(k.leagues, \\"Ligues\\"),\\n#(k.contact, \\"Contact\\"),\\n#(k.email_label, \\"Courriel\\"),\\n```\\n\\nAt startup, `translations.build()` assembles these into a nested dictionary (outer key is language code, inner key is translation key). This dictionary gets stored in the application context and threaded into every request. Lookup is two hash table reads, effectively instant.\\n\\n**In pages**, we partial-apply the lookup function for the current language:\\n\\n```gleam\\nlet t = t.t(rc.translations, rc.lang, _)\\n\\n// Then just call t() with key constants\\nelement.text(t(k.leagues))   // \\"Leagues\\" or \\"Ligues\\"\\nelement.text(t(k.contact))  // \\"Contact\\" (same in both languages!)\\n```\\n\\nThis is clean, type-safe, and impossible to mess up at runtime. If a key is missing from a language file, the UI shows `\\"[missing: postal_code_label]\\"` so it\'s immediately clear something needs to be fixed. Much better than a silent blank.\\n\\n### Catching Problems at Compile and Test Time\\n\\nUsing constants instead of raw strings means a typo like `t(k.legues)` is a compile error because the constant doesn\'t exist. That alone eliminates an entire class of bugs we dealt with in Version 2.\\n\\nWe also have a test that verifies every English key has a French counterpart and vice versa:\\n\\n```gleam\\npub fn should_have_same_keys_in_en_and_fr_test() {\\n  let en_keys = en.all() |> dict.keys() |> set.from_list()\\n  let fr_keys = fr.all() |> dict.keys() |> set.from_list()\\n  set.difference(en_keys, fr_keys) |> should.equal(set.new())\\n  set.difference(fr_keys, en_keys) |> should.equal(set.new())\\n}\\n```\\n\\nAdding a key to English without adding it to French fails the test suite. No more discovering untranslated strings in production.\\n\\nWe also have a script that checks for keys defined but never actually used in any page or template (dead key detection). Between the compiler, the parity test, and the unused key checker, translation problems are caught long before they reach users.\\n\\nNotice how small the test surface is. Because Gleam\'s type system handles so much at compile time, our tests focus on validating design decisions and business logic rather than guarding against runtime surprises. In Version 2 with Rails, a lot of test effort goes toward catching things that a type system would prevent: nil values, wrong argument types, missing method calls. In Gleam, the compiler handles all of that, so our translation tests are purely about the logic we actually care about: do all languages have the same keys? Does the fallback behavior work correctly?\\n\\n## Version 3: Content Translations\\n\\nContent translations (the user-entered data) take a different approach. Instead of per-language columns, each translatable table has a single `translations` JSON column:\\n\\n```json\\n{\\"fr\\": {\\"name\\": \\"Ligue du lundi\\", \\"summary\\": \\"R\xe9sum\xe9 en fran\xe7ais\\"}}\\n```\\n\\nThe primary language value lives in the regular column (`name`, `summary`). Only secondary language overrides go in the JSON. This means:\\n\\n- **Primary language reads are free.** No JSON parsing needed, just read the column.\\n- **No translations? No overhead.** The column is `NULL`.\\n- **Adding translatable fields requires zero schema changes.** Just start putting the field name in the JSON.\\n- **Adding a third language is just another key in the JSON.** No migration needed.\\n\\nThe resolution logic is straightforward: if the user is viewing in the primary language, return the regular column. If they\'re viewing in a secondary language, look it up in the JSON. If it\'s not there, fall back to the primary language value. Every field degrades gracefully. A missing French translation shows the English text rather than nothing.\\n\\n```gleam\\n// Parse once per record\\nlet parsed = i18n.parse(league.data.translations)\\n\\n// Resolve each field for the current language\\nlet name = i18n.resolve(league.data.name, parsed, lang, primary_lang, \\"name\\")\\n```\\n\\nThis solves the blank-vs-missing ambiguity from Version 2: if a field isn\'t in the `translations` JSON, it simply hasn\'t been translated yet, and the primary language value is shown. No guessing.\\n\\n## Language Routing\\n\\nLanguage selection comes from the URL path, not cookies or browser headers. This keeps things deterministic and shareable. A French URL always shows French content:\\n\\n- `/leagues` - primary language (no prefix)\\n- `/fr/leagues` - French (secondary language prefix)\\n- `/en/leagues` - redirects to `/leagues` (primary language never gets a prefix)\\n\\nThe router extracts the language from the first path segment, stores it in the request context, and every page and API handler downstream uses it. Clean, predictable, and great for SEO.\\n\\n## What\'s Next\\n\\nThe i18n foundation is in place. As we build out more features (admin interfaces, registration flows, email notifications) we\'ll add keys to the app label system and the `translations` JSON column to more tables. The system is designed to scale to thousands of keys without any architectural changes.\\n\\n---\\n\\n*This is Part 2 of the Curling IO Foundation series. Next up: [passwordless authentication and multi-email support](/blog/passwordless-auth-done-right).*"},{"id":"the-next-version-of-curling-io","metadata":{"permalink":"/blog/the-next-version-of-curling-io","source":"@site/blog/2026-02-12-the-next-version-of-curling-io.md","title":"The Next Version of Curling IO","description":"We\'re building the next version of Curling IO - same features, same experience, stronger foundation. After over a decade of serving hundreds of curling organizations across Canada, the US, and internationally, we\'re investing in technical upgrades that set Curling IO up for the next 20+ years.","date":"2026-02-12T00:00:00.000Z","tags":[{"inline":true,"label":"foundation","permalink":"/blog/tags/foundation"},{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"},{"inline":true,"label":"gleam","permalink":"/blog/tags/gleam"},{"inline":true,"label":"sqlite","permalink":"/blog/tags/sqlite"},{"inline":true,"label":"scaling","permalink":"/blog/tags/scaling"}],"readingTime":7.88,"hasTruncateMarker":true,"authors":[{"name":"Dave Rapin","title":"Founder @ Curling IO","imageURL":"https://avatars.githubusercontent.com/u/1202?v=4","key":"dave","page":null}],"frontMatter":{"slug":"the-next-version-of-curling-io","title":"The Next Version of Curling IO","authors":["dave"],"tags":["foundation","architecture","gleam","sqlite","scaling"]},"unlisted":false,"prevItem":{"title":"Bilingual by Design","permalink":"/blog/bilingual-by-design"}},"content":"We\'re building the next version of Curling IO - same features, same experience, stronger foundation. After over a decade of serving hundreds of curling organizations across Canada, the US, and internationally, we\'re investing in technical upgrades that set Curling IO up for the next 20+ years.\\n\\nThis is Part 1 of a series of technical posts documenting our journey and decisions as we build.\\n\\n\x3c!--truncate--\x3e\\n\\n## How This Affects You\\n\\n**For club managers:** Curling IO isn\'t changing from your perspective. We\'re upgrading the technical infrastructure behind the scenes - no downtime, no disruption, no action required from you. Your data stays exactly where it is. When the upgrade is complete (thoroughly tested and proven), the transition will be seamless. You\'ll have the same Curling IO you know, even faster and more reliable.\\n\\n**For curlers:** You won\'t notice the technology change. Registration, scoring, schedules, results - everything works the same way. You might notice things feel snappier, especially during peak registration times or when checking live scores at major competitions.\\n\\n## Why a New Foundation?\\n\\nCurling IO has been serving curling clubs since late 2014. We upgraded the platform once already in 2019, and our Version 2 system has been running successfully on Rails ever since. Everything works, clubs are happy, and growth is strong. So why invest in a new foundation?\\n\\nBecause we\'re planning to be here for the long haul. This new foundation ensures Curling IO can serve curling clubs not just for the next few years, but for the next 20+ years. While competitors come and go, we\'re investing in infrastructure built to last and evolve with the sport.\\n\\n**Three key reasons:**\\n\\n1. **AI Agent APIs** - We\'re adding new APIs specifically designed for AI agents to work with easily. Your existing web interface isn\'t changing - these are additional capabilities on top of what you already use. As AI assistants become ubiquitous (whether you love them or not), we\'re designing for that reality. Users are already asking ChatGPT and Claude to help them register for leagues or check schedules - we want those interactions to work reliably.\\n\\n2. **Concurrency and correctness** - As the platform grows, we need stronger guarantees around correctness and performance. We want a tech stack that can handle massive concurrency - both during peak registration periods and during large traffic spikes for scoring and results at provincial and national competitions like the Scotties and Brier. It needs to prevent runtime errors and scale efficiently as the sport grows.\\n\\n3. **Easier developer onboarding** - We want a codebase that\'s easy to hand off between developers. Type safety and functional patterns make code self-documenting - new developers (with help from AI coding assistants) can jump in and contribute safely without deep institutional knowledge. Gleam\'s deterministic patterns are much easier for AI assistants to reason about than dynamic languages, which means faster onboarding and more productive collaboration between developers and their AI tools. This significantly reduces key-person dependency.\\n\\n## Choosing the Tech Stack\\n\\nGiven our goals - agent-native APIs, clean architecture, and battle-tested reliability at scale - we need a stack that can deliver:\\n\\n**What we\'re looking for**\\n- **Type safety** - Catch errors at compile time, not in production\\n- **Massive concurrency** - Handle thousands of simultaneous registrations\\n- **Functional patterns** - Predictable, testable code that developers can reason about\\n- **Shared types** - Same data structures on client and server\\n- **Proven at scale** - Used in production by major companies\\n\\n**Why Gleam?**\\n\\n<a href=\\"https://gleam.run\\" target=\\"_blank\\">Gleam</a> checks every box. It\'s a type-safe functional language that compiles to both Erlang (for the server) and JavaScript (for the client). You get:\\n\\n- **<a href=\\"https://www.erlang.org/blog/a-brief-beam-primer/\\" target=\\"_blank\\">BEAM VM</a> reliability** - The same runtime that powers WhatsApp (billions of messages with ~50 engineers) and Discord (millions of concurrent users). Built-in fault tolerance and lightweight processes.\\n- **ML-family type system** - Stronger than Elixir, catches entire classes of bugs at compile time\\n- **<a href=\\"https://lustre.build\\" target=\\"_blank\\">Lustre</a> for frontend** - An <a href=\\"https://elm-lang.org\\" target=\\"_blank\\">Elm</a>-architecture framework for Gleam that compiles to JavaScript. We already love Elm for our current frontend apps, and Lustre brings that same architecture everywhere. Same types from database to UI, all type-safe.\\n- **Simple language** - Focused, consistent, easy to reason about. Perfect for building deterministic APIs.\\n\\n**What about other options?**\\n\\nWe didn\'t jump straight to Gleam. We seriously considered several other stacks:\\n\\n**<a href=\\"https://postgrest.org\\" target=\\"_blank\\">PostgREST</a> + Elm/Lustre** - This was a very serious contender using tools we\'re already familiar with. PostgREST provides instant APIs from your PostgreSQL schema, and Elm/Lustre provides type-safe UI. But we\'d need something else for background jobs (like Go), and the tooling for building, debugging, and testing PostgreSQL functions isn\'t great. The multi-language setup felt fragmented.\\n\\n**<a href=\\"https://safe-stack.github.io\\" target=\\"_blank\\">F# SAFE Stack</a>** - F# is a fantastic functional language with a solid .NET ecosystem. The SAFE stack (Suave/Saturn, Azure/AWS, Fable, Elmish) offers full-stack type safety with The Elm Architecture (TEA) on the frontend. We really liked this option, but ultimately chose Gleam for its BEAM VM benefits and simpler deployment story.\\n\\n**TypeScript + Node + React** - The obvious choice given its massive ecosystem and the sheer volume of material AI agents can draw from. We\'ve been using React off and on since 2014 and like Redux (which is Elm-inspired) for the frontend. But JavaScript/TypeScript has issues we couldn\'t get past: nulls everywhere, a type system that feels bolted on (TypeScript\'s safety is opt-out with `any`, `as`, and `!`), relentless library churn, and recurring npm supply chain vulnerabilities. React itself has become overly complex. Popularity is a real advantage, but it wasn\'t enough to outweigh the correctness and simplicity we wanted.\\n\\n**BEAM was the killer feature.** None of these other options came close to what the BEAM VM offers: rock-solid concurrency, fault tolerance, and proven scalability (WhatsApp, Discord, etc.). Gleam gives us BEAM on the backend with familiar functional patterns (like Elm) on the frontend, all in a single language.\\n\\n**Why not stick with Rails?**\\n\\nTo be clear: we love <a href=\\"https://rubyonrails.org\\" target=\\"_blank\\">Ruby on Rails</a>. It\'s been amazing for rapid development and has scaled well for our needs. For heavier interactive features, we\'ve already been using Elm for frontend apps like Bracket Builder, Scheduling, Scoring, and Results widgets, with PostgREST providing clean APIs on the backend. This functional programming approach has worked really well.\\n\\nBut for where we\'re headed, we need:\\n- Compile-time safety (Ruby is dynamically typed)\\n- BEAM-level concurrency (Rails doesn\'t even come close)\\n- Shared client/server types (Rails is backend-only)\\n- Functional patterns built-in (Rails is object-oriented)\\n\\nThis isn\'t about Rails being bad - we\'ve been building with it since version 1.2 and nothing else lets you iterate that fast. But over time we\'ve moved towards functional, compiled, typed languages because runtime errors are the absolute worst to debug and fix. Gleam gives us that correctness without giving up the developer experience we love about Rails.\\n\\n## SQLite Over PostgreSQL\\n\\n**This one surprised us.**\\n\\nCurling IO Version 2 runs on PostgreSQL. We assumed we\'d use Postgres for Version 3. But we\'re betting on <a href=\\"https://sqlite.org\\" target=\\"_blank\\">SQLite</a> instead.\\n\\n**Why SQLite?**\\n\\n- **Isolated databases** - Clean separation of concerns with dedicated database files\\n- **In-process speed** - Zero network latency between app and database\\n- **Operational simplicity** - No database server to manage, tune, or cluster\\n- **Cost savings** - Orders of magnitude cheaper than <a href=\\"https://www.crunchydata.com/products/crunchy-bridge\\" target=\\"_blank\\">managed Postgres</a>\\n- **<a href=\\"https://litestream.io\\" target=\\"_blank\\">Litestream</a> backups** - Continuous replication to offsite storage\\n\\n**What about scale?**\\n\\nFor the same infrastructure budget as Rails + PostgreSQL, we expect Gleam + SQLite to handle roughly:\\n- 1,000x more concurrent connections\\n- 100x the data volume\\n- 100x the throughput during peak traffic (registrations, live scoring)\\n\\nThese numbers sound outrageous, but they aren\'t pulled out of thin air. BEAM processes are ~2KB each vs Rails threads at ~1MB - that\'s where the 1,000x connection multiplier comes from. And eliminating network round-trips to a separate database server (SQLite runs in-process) while leveraging BEAM\'s lightweight concurrency model accounts for the throughput gains. These are well-documented characteristics of the technology, not optimistic guesses.\\n\\nThat said, we\'ll be validating everything with extensive benchmarking and real-world load tests as we build.\\n\\nIf SQLite doesn\'t scale as expected, we\'ll just stick with PostgreSQL - an equally great database.\\n\\n## Vertical-First Scaling\\n\\nOur scaling strategy is simple: start on a single powerful server and scale up from there.\\n\\n- One server with co-located app + database (one thing to deploy, backup, monitor)\\n- Warm backup server + continuous offsite backups\\n- Scale up CPU and RAM as we grow\\n- No distributed systems complexity until actually needed\\n\\nIf we ever outgrow a single server, we have a clean path to splitting things up. But with BEAM\'s concurrency and SQLite\'s in-process speed, we expect that to be a long way off.\\n\\n## What\'s Next\\n\\nWe\'ll be building this out over the coming months alongside the existing platform. Curling IO Version 2 isn\'t going anywhere - it continues to run and receive updates as usual. When Version 3 is ready and thoroughly tested, we\'ll transition everyone over at once - a clean, coordinated switch rather than a drawn-out process. We won\'t make that switch until we\'re confident everything is solid.\\n\\n---\\n\\n*This is Part 1 of the Curling IO Foundation series. Next up: [bilingual support with compile-time guarantees](/blog/bilingual-by-design).*"}]}}')}}]);